import torch
from transformers import AutoTokenizer, AutoModelForCausalLM
from PIL import Image

# Ensure the function leverages GPU if available
def generate_text_from_image(image_tensor):
    """
    Convert a 3x224x224 RGB image tensor to a text description using LLaVA.
    
    Args:
        image_tensor (torch.Tensor): A tensor of shape (3, 224, 224) representing the RGB image.

    Returns:
        str: Text description generated by the LLaVA model.
    """
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # Load the tokenizer and model
    tokenizer = AutoTokenizer.from_pretrained("path_to_llama_tokenizer")
    model = AutoModelForCausalLM.from_pretrained("path_to_llama_model").to(device)

    # Preprocessing image tensor
    if image_tensor.ndimension() != 3 or image_tensor.size(0) != 3 or image_tensor.size(1) != 224 or image_tensor.size(2) != 224:
        raise ValueError("Input tensor must have the shape (3, 224, 224)")

    # Add batch dimension and move to GPU
    image_tensor = image_tensor.unsqueeze(0).to(device)

    # Simulate feature extraction (replace with actual LLaVA feature extraction if available)
    with torch.no_grad():
        image_features = image_tensor.mean(dim=(2, 3))  # Placeholder for actual LLaVA feature extractor

    # Prepare input text prompt for LLaVA
    prompt = "Describe the image:"
    inputs = tokenizer(prompt, return_tensors="pt").to(device)

    # Generate text from image features using LLaVA
    # Placeholder for LLaVA; actual implementation would concatenate image_features with inputs
    outputs = model.generate(
        inputs.input_ids,
        max_length=50,
        num_beams=5,
        no_repeat_ngram_size=2,
        early_stopping=True
    )

    # Decode generated text
    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)

    return generated_text



if __name__ == "__main__":
    # 生成一个随机的形状为 (3, 224, 224) 的图像 Tensor
    image_tensor = torch.rand(3, 224, 224)

    # 调用 generate_text_from_image 函数
    try:
        description = generate_text_from_image(image_tensor)
        print("Generated description:", description)
    except Exception as e:
        print("Error:", e)